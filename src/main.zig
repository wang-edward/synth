const std = @import("std");
const rl = @import("raylib");
const c = @cImport(@cInclude("soundio/soundio.h"));
const audio = @import("audio.zig");
const uni = @import("uni.zig");
const queue = @import("queue.zig");
const midi = @import("midi.zig");
const ops = @import("ops.zig");
const interface = @import("interface.zig");
const project = @import("project.zig");

var g_note_queue: midi.NoteQueue = .{};
var g_playhead: u64 = 0;
var g_playing: bool = false;
var g_recording: bool = false;
var g_timeline: project.Timeline = undefined;
var g_op_queue: ops.OpQueue = .{};
var g_active_track: usize = 0;

// Recording state
var g_held_notes: [128]?midi.Frame = .{null} ** 128; // note -> start frame
var g_record_buffer: std.ArrayListUnmanaged(midi.Note) = .{};

inline fn getActiveTrack() *project.Track {
    return &g_timeline.tracks[g_active_track];
}

var gpa = std.heap.GeneralPurposeAllocator(.{}){};
const A = gpa.allocator();

// temp allocator for audio callback
var scratch_mem: [512 * 1024]u8 = undefined;
var scratch_fba = std.heap.FixedBufferAllocator.init(&scratch_mem);
var context: audio.Context = undefined;

var root: audio.Node = undefined;

// libsoundio
var sio: ?*c.SoundIo = null;
var out: ?*c.SoundIoOutStream = null;

// shared sio pointer to allow main to kill sio
var g_sio_ptr = std.atomic.Value(?*c.SoundIo).init(null);

// run flag for audio thread
var g_run_audio = std.atomic.Value(bool).init(true);

fn must(ok: c_int) void {
    if (ok != c.SoundIoErrorNone) @panic("soundio error");
}

fn write_callback(
    maybe_outstream: ?[*]c.SoundIoOutStream,
    _min: c_int,
    max: c_int,
) callconv(.c) void {
    // exit early if program ended
    if (!g_run_audio.load(.acquire)) return;

    _ = _min;
    const outstream: *c.SoundIoOutStream = &maybe_outstream.?[0];
    const layout = &outstream.layout;
    const chans: usize = @intCast(layout.channel_count);

    var frames_left = max;
    var midi_notes: [midi.MAX_NOTES_PER_BLOCK]midi.NoteMsg = undefined;

    // Rebuild the temp arena for this callback
    scratch_fba = std.heap.FixedBufferAllocator.init(&scratch_mem);
    context.arena = std.heap.ArenaAllocator.init(scratch_fba.allocator());

    while (frames_left > 0) {
        var frame_count = frames_left;

        var areas: [*]c.SoundIoChannelArea = undefined;
        must(c.soundio_outstream_begin_write(maybe_outstream, @ptrCast(&areas), &frame_count));
        if (frame_count == 0) break;

        // process note
        while (g_note_queue.pop()) |msg| {
            switch (msg) {
                .Off => |note| {
                    getActiveTrack().synth.noteOff(note);
                    // Record note off
                    if (g_recording and g_playing) {
                        if (g_held_notes[note]) |start| {
                            g_record_buffer.append(A, .{
                                .start = start,
                                .end = g_playhead,
                                .note = note,
                            }) catch {};
                            g_held_notes[note] = null;
                        }
                    }
                },
                .On => |note| {
                    getActiveTrack().synth.noteOn(note);
                    // Record note on
                    if (g_recording and g_playing) {
                        g_held_notes[note] = g_playhead;
                    }
                },
            }
        }

        // process Ops
        while (g_op_queue.pop()) |op| {
            std.debug.print("op: {}\n", .{op});
            switch (op) {
                .Playback => |p| switch (p) {
                    .TogglePlay => {
                        for (g_timeline.tracks[0..g_timeline.track_count]) |t| {
                            t.synth.allNotesOff();
                        }
                        // if recording and playing, stop both
                        if (g_recording and g_playing) {
                            g_recording = false;
                            g_playing = false;
                            g_held_notes = .{null} ** 128;
                            g_record_buffer.clearRetainingCapacity();
                            std.debug.print("stopped recording and playback\n", .{});
                        } else {
                            g_playing = !g_playing;
                            std.debug.print("playback: {s}\n", .{if (g_playing) "play" else "pause"});
                        }
                    },
                    .Reset => {
                        for (g_timeline.tracks[0..g_timeline.track_count]) |t| {
                            t.synth.allNotesOff();
                        }
                        g_playhead = 0;
                    },
                    .Seek => |frame| {
                        for (g_timeline.tracks[0..g_timeline.track_count]) |t| {
                            t.synth.allNotesOff();
                        }
                        g_playhead = frame;
                    },
                },
                .Record => |r| switch (r) {
                    .ToggleRecord => |track_idx| {
                        if (g_recording) {
                            // stop recording: flush notes to track
                            if (g_record_buffer.items.len > 0) {
                                g_timeline.tracks[track_idx].player.appendNotes(
                                    A,
                                    g_record_buffer.items,
                                ) catch {};
                                g_record_buffer.clearRetainingCapacity();
                            }
                            // Clear held notes
                            g_held_notes = .{null} ** 128;
                            g_recording = false;
                            if (g_playing) g_playing = false;
                            std.debug.print("recording stopped, playing stopped, flushed to track {}\n", .{track_idx});
                        } else if (!g_playing) {
                            // not playing and not recording: start both
                            g_playing = true;
                            g_recording = true;
                            std.debug.print("started recording and playback on track {}\n", .{track_idx});
                        } else {
                            // nlaying but not recording: just start recording
                            g_recording = true;
                            std.debug.print("recording started on track {}\n", .{track_idx});
                        }
                    },
                },
            }
        }

        // render one block (mono) from the graph
        context.beginBlock();
        const mono = context.tmp().alloc(audio.Sample, @intCast(frame_count)) catch unreachable;
        root.v.process(root.ptr, &context, mono);

        // copy mono audio to all channels
        var f: c_int = 0;
        while (f < frame_count) : (f += 1) {
            const s = mono[@intCast(f)];
            var ch: usize = 0;
            while (ch < chans) : (ch += 1) {
                const step: usize = @intCast(areas[ch].step);
                const fi: usize = @intCast(f);
                const ptr = areas[ch].ptr + step * fi;
                const sample_ptr: *f32 = @ptrCast(@alignCast(ptr));
                sample_ptr.* = s;
            }
        }

        // advance playhead
        if (g_playing) {
            const start = g_playhead;
            g_playhead += @intCast(frame_count);

            for (g_timeline.tracks[0..g_timeline.track_count]) |*track| {
                const n = track.player.advance(start, g_playhead, &midi_notes);
                for (midi_notes[0..n]) |msg| {
                    switch (msg) {
                        .Off => |note| track.synth.noteOff(note),
                        .On => |note| track.synth.noteOn(note),
                    }
                }
            }
        }

        frames_left -= frame_count;
        must(c.soundio_outstream_end_write(maybe_outstream));
    }
}

fn underflow_callback(_: ?[*]c.SoundIoOutStream) callconv(.c) void {
    unreachable;
}

// =============================== Audio thread entry ==================================
fn audioThreadMain() !void {
    // SoundIO setup
    sio = c.soundio_create();
    if (sio == null) return error.NoMem;
    g_sio_ptr.store(sio, .release);
    defer {
        g_sio_ptr.store(null, .release); // clear
        if (sio) |p| c.soundio_destroy(p);
        sio = null;
    }
    must(c.soundio_connect(sio));
    c.soundio_flush_events(sio);
    const idx = c.soundio_default_output_device_index(sio);
    if (idx < 0) return error.NoOutputDeviceFound;
    const dev = c.soundio_get_output_device(sio, idx) orelse return error.NoMem;
    defer c.soundio_device_unref(dev);
    out = c.soundio_outstream_create(dev) orelse return error.NoMem;
    out.?.*.format = c.SoundIoFormatFloat32NE;
    out.?.*.write_callback = write_callback;
    out.?.*.underflow_callback = underflow_callback;
    // TODO make sample rate setting better
    out.?.*.sample_rate = 48_000;
    out.?.*.software_latency = 0.02;
    must(c.soundio_outstream_open(out.?));

    // Init graph context with chosen sample rate
    const sr: f32 = @floatFromInt(out.?.*.sample_rate);
    const bpm: f32 = 120;
    context = audio.Context.init(scratch_fba.allocator(), sr, bpm);

    must(c.soundio_outstream_start(out.?));

    // lesynth setup
    const tempo: f32 = 120;
    const notes = [_]midi.Note{
        .{ .start = midi.beatsToFrames(0.0, tempo, &context), .end = midi.beatsToFrames(0.9, tempo, &context), .note = 60 },
        .{ .start = midi.beatsToFrames(1.0, tempo, &context), .end = midi.beatsToFrames(1.9, tempo, &context), .note = 60 },
        .{ .start = midi.beatsToFrames(2.0, tempo, &context), .end = midi.beatsToFrames(2.9, tempo, &context), .note = 67 },
        .{ .start = midi.beatsToFrames(3.0, tempo, &context), .end = midi.beatsToFrames(3.9, tempo, &context), .note = 67 },
        .{ .start = midi.beatsToFrames(4.0, tempo, &context), .end = midi.beatsToFrames(4.9, tempo, &context), .note = 69 },
        .{ .start = midi.beatsToFrames(5.0, tempo, &context), .end = midi.beatsToFrames(5.9, tempo, &context), .note = 69 },
        .{ .start = midi.beatsToFrames(6.0, tempo, &context), .end = midi.beatsToFrames(7.9, tempo, &context), .note = 67 },
        .{ .start = midi.beatsToFrames(8.0, tempo, &context), .end = midi.beatsToFrames(8.9, tempo, &context), .note = 65 },
        .{ .start = midi.beatsToFrames(9.0, tempo, &context), .end = midi.beatsToFrames(9.9, tempo, &context), .note = 65 },
        .{ .start = midi.beatsToFrames(10.0, tempo, &context), .end = midi.beatsToFrames(10.9, tempo, &context), .note = 64 },
        .{ .start = midi.beatsToFrames(11.0, tempo, &context), .end = midi.beatsToFrames(11.9, tempo, &context), .note = 64 },
        .{ .start = midi.beatsToFrames(12.0, tempo, &context), .end = midi.beatsToFrames(12.9, tempo, &context), .note = 62 },
        .{ .start = midi.beatsToFrames(13.0, tempo, &context), .end = midi.beatsToFrames(13.9, tempo, &context), .note = 62 },
        .{ .start = midi.beatsToFrames(14.0, tempo, &context), .end = midi.beatsToFrames(15.9, tempo, &context), .note = 60 },
    };
    const bass_notes = [_]midi.Note{
        .{ .start = midi.beatsToFrames(0.0, tempo, &context), .end = midi.beatsToFrames(2.0, tempo, &context), .note = 48 },
        .{ .start = midi.beatsToFrames(2.0, tempo, &context), .end = midi.beatsToFrames(4.0, tempo, &context), .note = 48 },
        .{ .start = midi.beatsToFrames(4.0, tempo, &context), .end = midi.beatsToFrames(6.0, tempo, &context), .note = 43 },
        .{ .start = midi.beatsToFrames(6.0, tempo, &context), .end = midi.beatsToFrames(8.0, tempo, &context), .note = 43 },
        .{ .start = midi.beatsToFrames(8.0, tempo, &context), .end = midi.beatsToFrames(10.0, tempo, &context), .note = 41 },
        .{ .start = midi.beatsToFrames(10.0, tempo, &context), .end = midi.beatsToFrames(12.0, tempo, &context), .note = 40 },
        .{ .start = midi.beatsToFrames(12.0, tempo, &context), .end = midi.beatsToFrames(14.0, tempo, &context), .note = 38 },
        .{ .start = midi.beatsToFrames(14.0, tempo, &context), .end = midi.beatsToFrames(16.0, tempo, &context), .note = 36 },
    };
    const notes_per_track = [_][]const midi.Note{ &notes, &bass_notes };

    g_timeline = try project.Timeline.init(A, 2, 4, &notes_per_track);
    defer g_timeline.deinit();
    root = g_timeline.asNode();

    defer g_record_buffer.deinit(A);

    while (g_run_audio.load(.acquire)) {
        c.soundio_wait_events(sio);
    }

    // close outstream before g_timeline.deinit(). this prevents audio callbacks from running when there's nothing to fill the buffer
    // defer doesn't work in this case because the notes depend on context.sr
    // can be fixed by creating g_timeline first and then appending notes instead of doing it in place like this
    if (out) |p| c.soundio_outstream_destroy(p);
    out = null;
}

fn keyToMidi(key: rl.KeyboardKey) ?u8 {
    return switch (key) {
        // --- white keys (A–L) ---
        .a => 48, // C3
        .s => 50, // D3
        .d => 52, // E3
        .f => 53, // F3
        .g => 55, // G3
        .h => 57, // A3
        .j => 59, // B3
        .k => 60, // C4
        .l => 62, // D4
        .semicolon => 64, // E4
        .apostrophe => 65, // F4

        // --- black keys (W–O) ---
        .w => 49, // C#3
        .e => 51, // D#3
        .t => 54, // F#3
        .y => 56, // G#3
        .u => 58, // A#3
        .o => 61, // C#4
        .p => 63, // D#4
        else => null,
    };
}

pub fn main() !void {
    defer _ = gpa.deinit();

    var audio_thread = try std.Thread.spawn(.{}, audioThreadMain, .{});
    defer {
        g_run_audio.store(false, .release);
        if (g_sio_ptr.load(.acquire)) |p| c.soundio_wakeup(p);
        audio_thread.join();
    }

    try interface.init();
    defer interface.deinit();
    const note_keys = [_]rl.KeyboardKey{
        .a, .w, .s, .e, .d,         .f,          .t, .g, .y, .h, .u, .j,
        .k, .o, .l, .p, .semicolon, .apostrophe,
    };

    var offset: i8 = 0;
    var key_state = std.AutoHashMap(rl.KeyboardKey, ?u8).init(A);
    defer key_state.deinit();
    for (note_keys) |k| try key_state.put(k, null);

    while (!rl.windowShouldClose()) {
        for (note_keys) |key| {
            const down = rl.isKeyDown(key);
            const active_note = key_state.get(key).?;

            if (down and active_note == null) {
                if (keyToMidi(key)) |base| {
                    const note: u8 = @intCast(@as(i16, base) + @as(i16, offset));
                    while (!g_note_queue.push(.{ .On = note })) {} // TODO remove blocking?
                    try key_state.put(key, note);

                    std.debug.print("key pressed {}\n", .{key});
                }
            } else if (!down and active_note != null) {
                while (!g_note_queue.push(.{ .Off = active_note.? })) {} // TODO remove blocking?
                try key_state.put(key, null);

                std.debug.print("key released {}\n", .{key});
            }
        }

        if (rl.isKeyPressed(.up)) {
            const curr = getActiveTrack().synth.params.get(.cutoff);
            std.debug.print("cutoff: {}\n", .{curr});
            getActiveTrack().synth.params.set(.cutoff, curr * 1.1);
        }
        if (rl.isKeyPressed(.down)) {
            const curr = getActiveTrack().synth.params.get(.cutoff);
            std.debug.print("cutoff: {}\n", .{curr});
            getActiveTrack().synth.params.set(.cutoff, curr * 0.9);
        }

        if (rl.isKeyPressed(.x)) offset += 12;
        if (rl.isKeyPressed(.z)) offset -= 12;

        if (rl.isKeyPressed(.space)) {
            while (!g_op_queue.push(.{ .Playback = .TogglePlay })) {}
        }

        if (rl.isKeyPressed(.backspace)) {
            while (!g_op_queue.push(.{ .Playback = .Reset })) {}
        }

        // r: toggle recording on active track
        if (rl.isKeyPressed(.r)) {
            while (!g_op_queue.push(.{ .Record = .{ .ToggleRecord = g_active_track } })) {}
        }

        // - / = : remove / add track
        if (rl.isKeyPressed(.minus)) {
            g_timeline.removeTrack(g_active_track);
            std.debug.print("removed track {}\n", .{g_active_track});
        }
        if (rl.isKeyPressed(.equal)) {
            g_timeline.addTrack() catch {};
            std.debug.print("added track {}\n", .{g_timeline.track_count - 1});
        }

        // [ / ] : switch active track
        if (rl.isKeyPressed(.left_bracket)) {
            if (g_active_track > 0) g_active_track -= 1;
            std.debug.print("current track: {}\n", .{g_active_track});
        }
        if (rl.isKeyPressed(.right_bracket)) {
            if (g_active_track < g_timeline.track_count - 1) g_active_track += 1;
            std.debug.print("current track: {}\n", .{g_active_track});
        }

        // 1: toggle LPF, 2: toggle Distortion, 3: toggle Delay
        if (rl.isKeyPressed(.one)) {
            getActiveTrack().togglePlugin(.lpf) catch |err| {
                std.debug.print("Failed to toggle LPF: {}\n", .{err});
            };
        }
        if (rl.isKeyPressed(.two)) {
            getActiveTrack().togglePlugin(.distortion) catch |err| {
                std.debug.print("Failed to toggle distortion: {}\n", .{err});
            };
        }
        if (rl.isKeyPressed(.three)) {
            getActiveTrack().togglePlugin(.delay) catch |err| {
                std.debug.print("Failed to toggle delay: {}\n", .{err});
            };
        }

        // draw UI
        interface.preRender();
        defer interface.postRender();
        {
            g_timeline.render();
        }
    }
}
